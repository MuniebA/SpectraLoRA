{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SpectraLoRA: Physics-Aware Fine-Tuning for Geospatial Foundation Models","text":"<p>SpectraLoRA is a specialized Parameter-Efficient Fine-Tuning (PEFT) library designed for multispectral satellite imagery. Unlike standard LoRA, which treats all input channels equally, SpectraLoRA introduces a Physics-Aware Gating Mechanism that dynamically routes information to specialized adapters based on the spectral signature of the terrain (e.g., Vegetation, Water, Urban).</p> <p>This architecture is designed to fine-tune massive Geospatial Foundation Models (like IBM/NASA Prithvi-100M) on consumer hardware while enforcing physical consistency in predictions.</p>"},{"location":"#system-architecture","title":"\ud83c\udfd7\ufe0f System Architecture","text":"<p>SpectraLoRA operates as a \"Sidecar\" to the frozen foundation model. It intercepts data flow to inject physics context without altering the pre-trained weights.</p>"},{"location":"#key-innovations","title":"Key Innovations","text":"<ol> <li>Spectral Fingerprinting: Calculates real-time physics indices (NDVI, NDWI, BSI) before the model runs.</li> <li>Mixture-of-Experts (MoE): A bank of specialized Low-Rank Adapters (e.g., one for forests, one for cities).</li> <li>Dynamic Gating: A lightweight router that blends adapters based on the material properties of the image patch.</li> </ol>"},{"location":"#visualizing-results","title":"\ud83d\uddbc\ufe0f Visualizing Results","text":"<p>SpectraLoRA is built to handle highly diverse, complex geographies\u2014from arid deserts to dense coastal urban infrastructure. The library includes built-in batch prediction tools to visualize the AI's 4-class segmentation (Barren, Vegetation, Water, Urban) side-by-side with true-color satellite imagery.</p> <p> (Example output showing true RGB imagery alongside the SpectraLoRA physics-routed prediction)</p>"},{"location":"#project-structure","title":"\ud83d\udcc2 Project Structure","text":"<pre><code>SpectraLoRA/\n\u251c\u2500\u2500 spectra_lora/               # The Core Library Package\n\u2502   \u251c\u2500\u2500 __init__.py             # API Exporter\n\u2502   \u251c\u2500\u2500 config.py               # Phase 1: Global Configuration &amp; Band Maps\n\u2502   \u251c\u2500\u2500 spectral_ops.py         # Phase 1: The Physics Engine (NDVI/BSI Math)\n\u2502   \u251c\u2500\u2500 gating_network.py       # Phase 2: The Neural Router (MLP)\n\u2502   \u251c\u2500\u2500 layers.py               # Phase 2: The Custom SpectraLoRALayer\n\u2502   \u251c\u2500\u2500 model_wrapper.py        # Phase 3: The Surgeon (Model Loader &amp; Injector)\n\u2502   \u2514\u2500\u2500 utils.py                # Helpers: GeoTIFF Loading &amp; Visualization\n\u2502\n\u251c\u2500\u2500 experiments/                # Execution Scripts &amp; Testing\n\u2502   \u251c\u2500\u2500 train.py                # Phase 4: Training Loop &amp; Context Patching\n\u2502   \u251c\u2500\u2500 evaluate.py             # Phase 4: Physics-Aware Evaluation Metrics\n\u2502   \u251c\u2500\u2500 predict.py              # Phase 5: Batch Inference &amp; Visualization tool\n\u2502   \u2514\u2500\u2500 predictions_output/     # Saved side-by-side RGB vs AI prediction plots\n\u2502\n\u251c\u2500\u2500 setup.py                    # PyPI Installation Configuration\n\u251c\u2500\u2500 requirements.txt            # Dependencies\n\u251c\u2500\u2500 LICENSE                     # MIT License\n\u2514\u2500\u2500 README.md                   # This file\n</code></pre>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<p>You can install the library directly via pip:</p> <pre><code>pip install spectralora\n</code></pre> <p>(Alternatively, clone the repository and run <code>pip install -r requirements.txt</code> for development).</p>"},{"location":"#usage-python-api","title":"Usage (Python API)","text":"<p>Use SpectraLoRA to upgrade a standard Prithvi model with physics-aware adapters:</p> <pre><code>from spectra_lora import load_prithvi_model, inject_spectra_lora\n\n# 1. Load the frozen Foundation Model (Prithvi-100M)\nmodel = load_prithvi_model()\n\n# 2. Perform Surgery: Inject SpectraLoRA layers\nmodel = inject_spectra_lora(model)\n\n# 3. The model is now ready for training!\n# Only the adapter parameters (approx 1-5%) are trainable.\n</code></pre>"},{"location":"#detailed-file-guide","title":"\ud83d\udcd6 Detailed File Guide","text":""},{"location":"#1-the-physics-core-spectra_lora","title":"1. The Physics Core (<code>spectra_lora/</code>)","text":"<ul> <li><code>spectral_ops.py</code>: The mathematical heart of the library. It takes raw satellite tensors and calculates 5 physics indices: NDVI (Vegetation), SAVI (Soil-Adjusted Vegetation), NDWI (Water), NDBI (Built-up), and BSI (Bare Soil). This ensures the model \"sees\" physics, not just pixels.</li> <li><code>config.py</code>: The blueprint. Defines the Band Map (Blue=0, NIR=3, etc.) to ensure calculations are accurate for the Prithvi model. It also sets LoRA hyperparameters (Rank=4, Alpha=8).</li> <li><code>utils.py</code>: Handles the messy parts of Geospatial AI. Contains <code>load_geotiff</code> to normalize 16-bit satellite data into float32 tensors, and visualization tools to debug the spectral fingerprint.</li> </ul>"},{"location":"#2-the-neural-architecture-spectra_lora","title":"2. The Neural Architecture (<code>spectra_lora/</code>)","text":"<ul> <li><code>gating_network.py</code>: A tiny Multi-Layer Perceptron (MLP). It takes the 5-dimensional physics vector from <code>spectral_ops</code> and outputs soft mixing weights (e.g., <code>[0.8, 0.1, 0.1]</code>) to control the adapters.</li> <li><code>layers.py</code>: The custom PyTorch module. It replaces standard Linear layers. It contains:</li> <li>The Frozen original weights.</li> <li>The Adapter Bank (3 parallel LoRA experts).</li> <li>The Gating Network.</li> <li>Logic: \\(Output = Frozen(x) + \\sum_{i} (Gate_i(z) \\cdot Adapter_i(x))\\)</li> </ul>"},{"location":"#3-the-integration-spectra_lora","title":"3. The Integration (<code>spectra_lora/</code>)","text":"<ul> <li><code>model_wrapper.py</code>: The \"Surgeon.\" It downloads the Prithvi architecture code dynamically from Hugging Face (since it's not in standard <code>transformers</code>), loads the weights, and recursively swaps Attention layers with <code>SpectraLoRALayer</code>.</li> <li><code>__init__.py</code>: Exposes the high-level API so you can import functions cleanly.</li> </ul>"},{"location":"#4-experiments-experiments","title":"4. Experiments (<code>experiments/</code>)","text":"<ul> <li><code>train.py</code>: The training engine. It includes a critical Runtime Patch (<code>patch_model_for_context</code>) that allows the model to access the global \"Physics Context\" without rewriting the original Prithvi code.</li> <li><code>evaluate.py</code>: A custom validator. Beyond standard mIoU, it calculates a \"Physics Violation Score\"\u2014counting how many times the model predicted \"Vegetation\" in a pixel where the NDVI was clearly \"Desert.\"</li> <li><code>predict.py</code>: A batch-processing visualization tool that iterates through <code>.tif</code> datasets and outputs RGB-vs-Prediction maps.</li> </ul>"},{"location":"#citation","title":"\ud83d\udcca Citation","text":"<p>If you use this code for your research, please cite:</p> <pre><code>@software{spectralora2026,\n  author = {Munieb Abdelrahman},\n  title = {SpectraLoRA: Band-Specific Low-Rank Adaptation for Geospatial Foundation Models},\n  year = {2026},\n  url = {[https://github.com/MuniebA/SpectraLoRA](https://github.com/MuniebA/SpectraLoRA)}\n}\n</code></pre>"},{"location":"api_reference/","title":"API Reference","text":""},{"location":"api_reference/#configuration","title":"Configuration","text":""},{"location":"api_reference/#spectra_loraconfigspectraconfig","title":"<code>spectra_lora.config.SpectraConfig</code>","text":"<p>The central dataclass controlling the library's hyperparameters.</p> <p>Attributes: * <code>BAND_MAP</code> (dict): Maps channel indices to their spectral names. Default assumes Prithvi-100M HLS ordering: <code>{'BLUE': 0, 'GREEN': 1, 'RED': 2, 'NIR': 3, 'SWIR': 4, 'SWIR2': 5}</code>. * <code>LORA_R</code> (int): The rank of the adapter matrices. Default: <code>4</code>. * <code>LORA_ALPHA</code> (int): The scaling factor. Default: <code>8</code>. * <code>NUM_ADAPTERS</code> (int): The number of expert adapters per layer. Default: <code>3</code>. * <code>GATE_HIDDEN_DIM</code> (int): The hidden dimension of the MLP router. Default: <code>32</code>. * <code>GATE_TEMPERATURE</code> (float): Controls the sharpness of the routing decision. Default: <code>1.0</code>.</p>"},{"location":"api_reference/#model-surgery","title":"Model Surgery","text":""},{"location":"api_reference/#load_prithvi_modelrepo_id-filename","title":"<code>load_prithvi_model(repo_id, filename)</code>","text":"<p>Downloads and initializes the bare Prithvi-100M Vision Transformer architecture.</p> <p>Returns: * <code>torch.nn.Module</code>: The frozen foundation model encoder.</p>"},{"location":"api_reference/#inject_spectra_loramodel-config","title":"<code>inject_spectra_lora(model, config)</code>","text":"<p>Recursively traverses a PyTorch model, finds the QKV (Query-Key-Value) linear layers within the Attention blocks, and replaces them with <code>SpectraLoRALayer</code>.</p> <p>Returns: * <code>torch.nn.Module</code>: The modified model, ready for training.</p>"},{"location":"api_reference/#the-neural-architecture","title":"The Neural Architecture","text":""},{"location":"api_reference/#spectra_loralayersspectraloralayer","title":"<code>spectra_lora.layers.SpectraLoRALayer</code>","text":"<p>The custom PyTorch module that wraps a frozen Linear layer and adds the physics-aware sidecar. </p> <p>Forward Pass Requirements: Because this layer requires the global physics context \\(z\\), standard PyTorch forward passes (which only pass \\(x\\)) will fail. You must implement a context manager or monkey-patch the forward pass in your training loop to supply \\(z\\).</p>"},{"location":"api_reference/#spectra_loragating_networkspectralgate","title":"<code>spectra_lora.gating_network.SpectralGate</code>","text":"<p>A Multi-Layer Perceptron (MLP) that maps the 5-dimensional physics vector to softmax routing probabilities for the adapter bank.</p>"},{"location":"api_reference/#utilities","title":"Utilities","text":""},{"location":"api_reference/#count_parametersmodel","title":"<code>count_parameters(model)</code>","text":"<p>Prints a statistical breakdown of the model, showing the exact efficiency gains (e.g., \"1.2% trainable parameters\") achieved by the LoRA injection.</p>"},{"location":"getting_started/","title":"Getting Started with SpectraLoRA","text":"<p>Welcome to the official documentation for SpectraLoRA, a Physics-Aware Parameter-Efficient Fine-Tuning (PEFT) library built for Geospatial Foundation Models. </p>"},{"location":"getting_started/#the-problem-with-standard-lora-in-geospatial-ai","title":"The Problem with Standard LoRA in Geospatial AI","text":"<p>Standard Low-Rank Adaptation (LoRA) is an incredible tool for text models (LLMs). However, when applied to multi-spectral satellite imagery, standard LoRA treats all input channels blindly. It applies the same learned weight updates regardless of whether it is looking at the Sahara Desert, the Amazon Rainforest, or the concrete skyline of Doha.</p>"},{"location":"getting_started/#the-spectralora-solution","title":"The SpectraLoRA Solution","text":"<p>SpectraLoRA introduces a Physics-Aware Mixture-of-Experts (MoE) architecture. Instead of one generic adapter, SpectraLoRA injects a bank of specialized LoRA adapters (e.g., an \"Urban Expert,\" a \"Water Expert,\" and a \"Vegetation Expert\"). </p> <p>Before the model processes an image patch, our Physics Engine calculates its Spectral Fingerprint (NDVI, NDWI, BSI, etc.). A tiny neural router then dynamically blends the adapters based on the physical properties of the terrain.</p>"},{"location":"getting_started/#core-equation","title":"Core Equation","text":"<p>The forward pass of a SpectraLoRALayer is defined as:</p> \\[Output = Frozen(x) + \\sum_{i=1}^{N} \\left( Gate_i(z) \\cdot Adapter_i(x) \\right) \\cdot \\frac{\\alpha}{r}\\] <p>Where: * \\(x\\) is the input tensor. * \\(z\\) is the 5-dimensional physics context vector. * \\(Gate_i(z)\\) is the soft-routing probability for expert \\(i\\). * \\(Adapter_i(x)\\) is the low-rank projection \\(B(A(x))\\).</p>"},{"location":"getting_started/#quick-installation","title":"Quick Installation","text":"<p>Install directly from PyPI: <pre><code>pip install spectralora\n</code></pre></p>"},{"location":"getting_started/#basic-usage","title":"Basic Usage","text":"<pre><code>from spectra_lora import load_prithvi_model, inject_spectra_lora\n\n# 1. Load the frozen foundation model\nmodel = load_prithvi_model()\n\n# 2. Inject the physics-aware adapters into the Attention layers\nmodel = inject_spectra_lora(model)\n\n# 3. Model is ready for your PyTorch training loop!\n</code></pre>"},{"location":"physics_engine/","title":"The Physics Engine (<code>spectral_ops</code>)","text":"<p>The Physics Engine is the heart of SpectraLoRA. It operates directly on raw, multi-spectral PyTorch tensors to extract physical meaning before the deep learning model sees the data. </p> <p>The engine currently tracks 5 distinct indices, optimized for both dense vegetation and arid, desert environments.</p>"},{"location":"physics_engine/#the-spectral-fingerprint","title":"The Spectral Fingerprint","text":"<p>The function <code>get_spectral_fingerprint(x, band_indices)</code> takes a satellite image tensor and returns a global context vector \\(z\\) of shape <code>(Batch, 5)</code>. This vector acts as the input to the Gating Network.</p>"},{"location":"physics_engine/#1-ndvi-normalized-difference-vegetation-index","title":"1. NDVI (Normalized Difference Vegetation Index)","text":"<p>The standard metric for identifying live green vegetation.</p> \\[NDVI = \\frac{NIR - Red}{NIR + Red + \\epsilon}\\]"},{"location":"physics_engine/#2-savi-soil-adjusted-vegetation-index","title":"2. SAVI (Soil-Adjusted Vegetation Index)","text":"<p>Crucial for arid regions (like Sudan or the Middle East) where bright sand reflects light and drowns out the chlorophyll signal of sparse shrubs.</p> \\[SAVI = \\frac{(NIR - Red) \\cdot (1 + L)}{NIR + Red + L + \\epsilon}\\] <p>(Default \\(L = 0.5\\))</p>"},{"location":"physics_engine/#3-ndwi-normalized-difference-water-index","title":"3. NDWI (Normalized Difference Water Index)","text":"<p>Used to identify open water bodies.</p> \\[NDWI = \\frac{Green - NIR}{Green + NIR + \\epsilon}\\]"},{"location":"physics_engine/#4-ndbi-normalized-difference-built-up-index","title":"4. NDBI (Normalized Difference Built-up Index)","text":"<p>Used to map urban areas, concrete, and asphalt.</p> \\[NDBI = \\frac{SWIR - NIR}{SWIR + NIR + \\epsilon}\\]"},{"location":"physics_engine/#5-bsi-bare-soil-index","title":"5. BSI (Bare Soil Index)","text":"<p>Distinguishes \"Bare Earth\" (Sand/Dirt) from \"Built Structures\". This is essential to stop the AI from confusing desert dunes with concrete buildings.</p> \\[BSI = \\frac{(SWIR + Red) - (NIR + Blue)}{(SWIR + Red) + (NIR + Blue) + \\epsilon}\\]"}]}